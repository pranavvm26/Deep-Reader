{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting editdistance==0.5.3\n",
      "  Downloading editdistance-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
      "\u001b[K     |████████████████████████████████| 179 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: editdistance\n",
      "Successfully installed editdistance-0.5.3\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numba==0.49.0\n",
      "  Downloading numba-0.49.0-cp37-cp37m-manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/site-packages (from numba==0.49.0) (1.18.4)\n",
      "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\n",
      "  Downloading llvmlite-0.32.1-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 20.6 MB/s eta 0:00:01     |███████████████████▍            | 12.2 MB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from numba==0.49.0) (46.2.0)\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.32.1 numba-0.49.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install editdistance==0.5.3\n",
    "!pip3 install numba==0.49.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import datetime\n",
    "\n",
    "from data.generator import DataGenerator, Tokenizer\n",
    "from network.model import HTRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 64, 1)\n",
    "max_text_length = 32\n",
    "charset_base = string.printable[:95]\n",
    "\n",
    "source='iam'\n",
    "arch =\"flor\" # puigcerver, bluche, flor,\n",
    "batch_size = 100\n",
    "type_of_run = 'train'\n",
    "if type_of_run == 'train':\n",
    "    train_model = False\n",
    "else:\n",
    "    train_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = os.path.join(\"/floyd/input/words_htr_onew\", f\"{source}_tvt.hdf5\")\n",
    "output_path = os.path.join(\"/floyd/home/output_words\", source, arch)\n",
    "target_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
    "\n",
    "assert os.path.isfile(source_path) or os.path.isfile(target_path)\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/floyd/input/words_htr_onew/iam_tvt.hdf5\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 128, 64, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 64, 32, 16)        160       \n",
      "_________________________________________________________________\n",
      "p_re_lu_90 (PReLU)           (None, 64, 32, 16)        16        \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 64, 32, 16)        112       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_75 (FullGa (None, 64, 32, 16)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 64, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "p_re_lu_91 (PReLU)           (None, 64, 32, 32)        32        \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 64, 32, 32)        224       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_76 (FullGa (None, 64, 32, 32)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 32, 8, 40)         10280     \n",
      "_________________________________________________________________\n",
      "p_re_lu_92 (PReLU)           (None, 32, 8, 40)         40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 32, 8, 40)         280       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_77 (FullGa (None, 32, 8, 40)         28880     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 32, 8, 40)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 32, 8, 48)         17328     \n",
      "_________________________________________________________________\n",
      "p_re_lu_93 (PReLU)           (None, 32, 8, 48)         48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 32, 8, 48)         336       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_78 (FullGa (None, 32, 8, 48)         41568     \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 32, 8, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 16, 2, 56)         21560     \n",
      "_________________________________________________________________\n",
      "p_re_lu_94 (PReLU)           (None, 16, 2, 56)         56        \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 16, 2, 56)         392       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_79 (FullGa (None, 16, 2, 56)         56560     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 16, 2, 56)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 16, 2, 64)         32320     \n",
      "_________________________________________________________________\n",
      "p_re_lu_95 (PReLU)           (None, 16, 2, 64)         64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 16, 2, 64)         448       \n",
      "_________________________________________________________________\n",
      "reshape_16 (Reshape)         (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_33 (Bidirectio (None, 32, 128)           49920     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32, 128)           16512     \n",
      "_________________________________________________________________\n",
      "bidirectional_34 (Bidirectio (None, 32, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 32, 98)            12642     \n",
      "=================================================================\n",
      "Total params: 392,050\n",
      "Trainable params: 390,770\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dtgen = DataGenerator(source=source_path,\n",
    "                      batch_size=batch_size,\n",
    "                      charset=charset_base,\n",
    "                      max_text_length=max_text_length,\n",
    "                      predict=train_model)\n",
    "\n",
    "model = HTRModel(architecture=arch,\n",
    "                 input_size=input_size,\n",
    "                 vocab_size=dtgen.tokenizer.vocab_size,\n",
    "                 beam_width=10,\n",
    "                 stop_tolerance=20,\n",
    "                 reduce_tolerance=15)\n",
    "\n",
    "model.compile(learning_rate=0.001)\n",
    "model.load_checkpoint(target=target_path)\n",
    "\n",
    "model.summary(output_path, \"summary.txt\")\n",
    "callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 53782\n",
      "Valid images: 5963\n",
      "Test images: 6603\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train images: {dtgen.size['train']}\")\n",
    "print(f\"Valid images: {dtgen.size['valid']}\")\n",
    "print(f\"Test images: {dtgen.size['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2639\n",
      "Epoch 00001: val_loss improved from inf to 8.97005, saving model to /floyd/home/output_words/iam/flor/checkpoint_weights.hdf5\n",
      "538/538 [==============================] - 114s 212ms/step - loss: 15.2639 - val_loss: 8.9701 - lr: 0.0010\n",
      "Epoch 2/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2591\n",
      "Epoch 00002: val_loss improved from 8.97005 to 8.96807, saving model to /floyd/home/output_words/iam/flor/checkpoint_weights.hdf5\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.2591 - val_loss: 8.9681 - lr: 0.0010\n",
      "Epoch 3/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2603\n",
      "Epoch 00003: val_loss did not improve from 8.96807\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.2603 - val_loss: 9.0513 - lr: 0.0010\n",
      "Epoch 4/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2357\n",
      "Epoch 00004: val_loss did not improve from 8.96807\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.2357 - val_loss: 8.9718 - lr: 0.0010\n",
      "Epoch 5/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2431\n",
      "Epoch 00005: val_loss did not improve from 8.96807\n",
      "538/538 [==============================] - 112s 207ms/step - loss: 15.2431 - val_loss: 9.0788 - lr: 0.0010\n",
      "Epoch 6/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2290\n",
      "Epoch 00006: val_loss improved from 8.96807 to 8.96506, saving model to /floyd/home/output_words/iam/flor/checkpoint_weights.hdf5\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.2290 - val_loss: 8.9651 - lr: 0.0010\n",
      "Epoch 7/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2145\n",
      "Epoch 00007: val_loss did not improve from 8.96506\n",
      "538/538 [==============================] - 112s 207ms/step - loss: 15.2145 - val_loss: 9.0560 - lr: 0.0010\n",
      "Epoch 8/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2012\n",
      "Epoch 00008: val_loss did not improve from 8.96506\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.2012 - val_loss: 9.0052 - lr: 0.0010\n",
      "Epoch 9/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.2001\n",
      "Epoch 00009: val_loss did not improve from 8.96506\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.2001 - val_loss: 8.9689 - lr: 0.0010\n",
      "Epoch 10/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.1917\n",
      "Epoch 00010: val_loss did not improve from 8.96506\n",
      "538/538 [==============================] - 112s 207ms/step - loss: 15.1917 - val_loss: 9.0097 - lr: 0.0010\n",
      "Epoch 11/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.1874\n",
      "Epoch 00011: val_loss did not improve from 8.96506\n",
      "538/538 [==============================] - 112s 207ms/step - loss: 15.1874 - val_loss: 8.9719 - lr: 0.0010\n",
      "Epoch 12/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.1784\n",
      "Epoch 00012: val_loss did not improve from 8.96506\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.1784 - val_loss: 8.9740 - lr: 0.0010\n",
      "Epoch 13/400\n",
      "538/538 [==============================] - ETA: 0s - loss: 15.1549\n",
      "Epoch 00013: val_loss did not improve from 8.96506\n",
      "538/538 [==============================] - 112s 208ms/step - loss: 15.1549 - val_loss: 8.9803 - lr: 0.0010\n",
      "Epoch 14/400\n",
      "137/538 [======>.......................] - ETA: 1:18 - loss: 15.1235"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "h = model.fit(x=dtgen.next_train_batch(),\n",
    "              epochs=400,\n",
    "              steps_per_epoch=dtgen.steps['train'],\n",
    "              validation_data=dtgen.next_valid_batch(),\n",
    "              validation_steps=dtgen.steps['valid'],\n",
    "              callbacks=callbacks,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "\n",
    "min_val_loss = min(val_loss)\n",
    "min_val_loss_i = val_loss.index(min_val_loss)\n",
    "\n",
    "time_epoch = (total_time / len(loss))\n",
    "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
    "\n",
    "t_corpus = \"\\n\".join([\n",
    "    f\"Total train images:      {dtgen.size['train']}\",\n",
    "    f\"Total validation images: {dtgen.size['valid']}\",\n",
    "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
    "    f\"Total time:              {total_time}\",\n",
    "    f\"Time per epoch:          {time_epoch}\",\n",
    "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
    "    f\"Total epochs:            {len(loss)}\",\n",
    "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
    "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
    "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
    "    lg.write(t_corpus)\n",
    "    print(t_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
